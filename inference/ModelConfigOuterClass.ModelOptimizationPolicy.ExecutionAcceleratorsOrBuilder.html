<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (21) on Fri Jan 30 10:07:11 UTC 2026 -->
<title>ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder (java-triton-sdk 1.0.1 API)</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="dc.created" content="2026-01-30">
<meta name="description" content="declaration: package: inference, class: ModelConfigOuterClass, class: ModelOptimizationPolicy, interface: ExecutionAcceleratorsOrBuilder">
<meta name="generator" content="javadoc/ClassWriterImpl">
<link rel="stylesheet" type="text/css" href="../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../script-dir/jquery-ui.min.css" title="Style">
<script type="text/javascript" src="../script.js"></script>
<script type="text/javascript" src="../script-dir/jquery-3.7.1.min.js"></script>
<script type="text/javascript" src="../script-dir/jquery-ui.min.js"></script>
</head>
<body class="class-declaration-page">
<script type="text/javascript">var pathtoroot = "../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top"><button id="navbar-toggle-button" aria-controls="navbar-top" aria-expanded="false" aria-label="Toggle navigation links"><span class="nav-bar-toggle-icon">&nbsp;</span><span class="nav-bar-toggle-icon">&nbsp;</span><span class="nav-bar-toggle-icon">&nbsp;</span></button>
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="nav-bar-cell1-rev">Class</li>
<li><a href="class-use/ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../deprecated-list.html">Deprecated</a></li>
<li><a href="../index-all.html">Index</a></li>
<li><a href="../help-doc.html#class">Help</a></li>
</ul>
<ul class="sub-nav-list-small">
<li>
<p>Summary:</p>
<ul>
<li>Nested</li>
<li>Field</li>
<li>Constr</li>
<li><a href="#method-summary">Method</a></li>
</ul>
</li>
<li>
<p>Detail:</p>
<ul>
<li>Field</li>
<li>Constr</li>
<li><a href="#method-detail">Method</a></li>
</ul>
</li>
</ul>
</div>
<div class="sub-nav">
<div id="navbar-sub-list">
<ul class="sub-nav-list">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method-summary">Method</a></li>
</ul>
<ul class="sub-nav-list">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method-detail">Method</a></li>
</ul>
</div>
<div class="nav-list-search"><a href="../search.html">SEARCH</a>
<input type="text" id="search-input" disabled placeholder="Search">
<input type="reset" id="reset-button" disabled value="reset">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="sub-title"><span class="package-label-in-type">Package</span>&nbsp;<a href="package-summary.html">inference</a></div>
<h1 title="Interface ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder" class="title">Interface ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder</h1>
</div>
<section class="class-description" id="class-description">
<dl class="notes">
<dt>All Superinterfaces:</dt>
<dd><code>com.google.protobuf.MessageLiteOrBuilder</code>, <code>com.google.protobuf.MessageOrBuilder</code></dd>
</dl>
<dl class="notes">
<dt>All Known Implementing Classes:</dt>
<dd><code><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators</a></code>, <code><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder</a></code></dd>
</dl>
<dl class="notes">
<dt>Enclosing class:</dt>
<dd><code><a href="ModelConfigOuterClass.ModelOptimizationPolicy.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy</a></code></dd>
</dl>
<hr>
<div class="type-signature"><span class="modifiers">public static interface </span><span class="element-name type-name-label">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder</span><span class="extends-implements">
extends com.google.protobuf.MessageOrBuilder</span></div>
</section>
<section class="summary">
<ul class="summary-list">
<!-- ========== METHOD SUMMARY =========== -->
<li>
<section class="method-summary" id="method-summary">
<h2>Method Summary</h2>
<div id="method-summary-table">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button id="method-summary-table-tab0" role="tab" aria-selected="true" aria-controls="method-summary-table.tabpanel" tabindex="0" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table', 3)" class="active-table-tab">All Methods</button><button id="method-summary-table-tab2" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab2', 3)" class="table-tab">Instance Methods</button><button id="method-summary-table-tab3" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab3', 3)" class="table-tab">Abstract Methods</button></div>
<div id="method-summary-table.tabpanel" role="tabpanel" aria-labelledby="method-summary-table-tab0">
<div class="summary-table three-column-summary">
<div class="table-header col-first">Modifier and Type</div>
<div class="table-header col-second">Method</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getCpuExecutionAccelerator(int)" class="member-name-link">getCpuExecutionAccelerator</a><wbr>(int&nbsp;index)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code>int</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getCpuExecutionAcceleratorCount()" class="member-name-link">getCpuExecutionAcceleratorCount</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a><wbr>&lt;<a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getCpuExecutionAcceleratorList()" class="member-name-link">getCpuExecutionAcceleratorList</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder.html" title="interface in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getCpuExecutionAcceleratorOrBuilder(int)" class="member-name-link">getCpuExecutionAcceleratorOrBuilder</a><wbr>(int&nbsp;index)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a><wbr>&lt;? extends <a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder.html" title="interface in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getCpuExecutionAcceleratorOrBuilderList()" class="member-name-link">getCpuExecutionAcceleratorOrBuilderList</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getGpuExecutionAccelerator(int)" class="member-name-link">getGpuExecutionAccelerator</a><wbr>(int&nbsp;index)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code>int</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getGpuExecutionAcceleratorCount()" class="member-name-link">getGpuExecutionAcceleratorCount</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a><wbr>&lt;<a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getGpuExecutionAcceleratorList()" class="member-name-link">getGpuExecutionAcceleratorList</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder.html" title="interface in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getGpuExecutionAcceleratorOrBuilder(int)" class="member-name-link">getGpuExecutionAcceleratorOrBuilder</a><wbr>(int&nbsp;index)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a><wbr>&lt;? extends <a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder.html" title="interface in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#getGpuExecutionAcceleratorOrBuilderList()" class="member-name-link">getGpuExecutionAcceleratorOrBuilderList</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">
&#64;&#64;    ..</div>
</div>
</div>
</div>
</div>
<div class="inherited-list">
<h3 id="methods-inherited-from-class-com.google.protobuf.MessageLiteOrBuilder">Methods inherited from interface&nbsp;com.google.protobuf.MessageLiteOrBuilder</h3>
<code>isInitialized</code></div>
<div class="inherited-list">
<h3 id="methods-inherited-from-class-com.google.protobuf.MessageOrBuilder">Methods inherited from interface&nbsp;com.google.protobuf.MessageOrBuilder</h3>
<code>findInitializationErrors, getAllFields, getDefaultInstanceForType, getDescriptorForType, getField, getInitializationErrorString, getOneofFieldDescriptor, getRepeatedField, getRepeatedFieldCount, getUnknownFields, hasField, hasOneof</code></div>
</section>
</li>
</ul>
</section>
<section class="details">
<ul class="details-list">
<!-- ============ METHOD DETAIL ========== -->
<li>
<section class="method-details" id="method-detail">
<h2>Method Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="getGpuExecutionAcceleratorList()">
<h3>getGpuExecutionAcceleratorList</h3>
<div class="member-signature"><span class="return-type"><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;<a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator</a>&gt;</span>&nbsp;<span class="element-name">getGpuExecutionAcceleratorList</span>()</div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on GPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
&#64;&#64;       "auto_mixed_precision", "gpu_io".
&#64;&#64;
&#64;&#64;       For "tensorrt", the following parameters can be specified:
&#64;&#64;         "precision_mode": The precision used for optimization.
&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
&#64;&#64;
&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
&#64;&#64;
&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
&#64;&#64;
&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
&#64;&#64;         can use temporarily during execution. Default value is 1GB.
&#64;&#64;
&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
&#64;&#64;       the model will try to use FP16 for better performance.
&#64;&#64;       This optimization can not be set with "tensorrt".
&#64;&#64;
&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
&#64;&#64;       be executed using TensorFlow Callable API to set input and output
&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
&#64;&#64;       object will be created on model creation and it will request all
&#64;&#64;       outputs for every model execution, which may impact the
&#64;&#64;       performance if a request does not require all outputs. This
&#64;&#64;       optimization will only take affect if the model instance is
&#64;&#64;       created with KIND_GPU.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code></div>
</section>
</li>
<li>
<section class="detail" id="getGpuExecutionAccelerator(int)">
<h3>getGpuExecutionAccelerator</h3>
<div class="member-signature"><span class="return-type"><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator</a></span>&nbsp;<span class="element-name">getGpuExecutionAccelerator</span><wbr><span class="parameters">(int&nbsp;index)</span></div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on GPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
&#64;&#64;       "auto_mixed_precision", "gpu_io".
&#64;&#64;
&#64;&#64;       For "tensorrt", the following parameters can be specified:
&#64;&#64;         "precision_mode": The precision used for optimization.
&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
&#64;&#64;
&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
&#64;&#64;
&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
&#64;&#64;
&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
&#64;&#64;         can use temporarily during execution. Default value is 1GB.
&#64;&#64;
&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
&#64;&#64;       the model will try to use FP16 for better performance.
&#64;&#64;       This optimization can not be set with "tensorrt".
&#64;&#64;
&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
&#64;&#64;       be executed using TensorFlow Callable API to set input and output
&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
&#64;&#64;       object will be created on model creation and it will request all
&#64;&#64;       outputs for every model execution, which may impact the
&#64;&#64;       performance if a request does not require all outputs. This
&#64;&#64;       optimization will only take affect if the model instance is
&#64;&#64;       created with KIND_GPU.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code></div>
</section>
</li>
<li>
<section class="detail" id="getGpuExecutionAcceleratorCount()">
<h3>getGpuExecutionAcceleratorCount</h3>
<div class="member-signature"><span class="return-type">int</span>&nbsp;<span class="element-name">getGpuExecutionAcceleratorCount</span>()</div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on GPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
&#64;&#64;       "auto_mixed_precision", "gpu_io".
&#64;&#64;
&#64;&#64;       For "tensorrt", the following parameters can be specified:
&#64;&#64;         "precision_mode": The precision used for optimization.
&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
&#64;&#64;
&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
&#64;&#64;
&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
&#64;&#64;
&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
&#64;&#64;         can use temporarily during execution. Default value is 1GB.
&#64;&#64;
&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
&#64;&#64;       the model will try to use FP16 for better performance.
&#64;&#64;       This optimization can not be set with "tensorrt".
&#64;&#64;
&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
&#64;&#64;       be executed using TensorFlow Callable API to set input and output
&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
&#64;&#64;       object will be created on model creation and it will request all
&#64;&#64;       outputs for every model execution, which may impact the
&#64;&#64;       performance if a request does not require all outputs. This
&#64;&#64;       optimization will only take affect if the model instance is
&#64;&#64;       created with KIND_GPU.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code></div>
</section>
</li>
<li>
<section class="detail" id="getGpuExecutionAcceleratorOrBuilderList()">
<h3>getGpuExecutionAcceleratorOrBuilderList</h3>
<div class="member-signature"><span class="return-type"><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;? extends <a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder.html" title="interface in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder</a>&gt;</span>&nbsp;<span class="element-name">getGpuExecutionAcceleratorOrBuilderList</span>()</div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on GPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
&#64;&#64;       "auto_mixed_precision", "gpu_io".
&#64;&#64;
&#64;&#64;       For "tensorrt", the following parameters can be specified:
&#64;&#64;         "precision_mode": The precision used for optimization.
&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
&#64;&#64;
&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
&#64;&#64;
&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
&#64;&#64;
&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
&#64;&#64;         can use temporarily during execution. Default value is 1GB.
&#64;&#64;
&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
&#64;&#64;       the model will try to use FP16 for better performance.
&#64;&#64;       This optimization can not be set with "tensorrt".
&#64;&#64;
&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
&#64;&#64;       be executed using TensorFlow Callable API to set input and output
&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
&#64;&#64;       object will be created on model creation and it will request all
&#64;&#64;       outputs for every model execution, which may impact the
&#64;&#64;       performance if a request does not require all outputs. This
&#64;&#64;       optimization will only take affect if the model instance is
&#64;&#64;       created with KIND_GPU.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code></div>
</section>
</li>
<li>
<section class="detail" id="getGpuExecutionAcceleratorOrBuilder(int)">
<h3>getGpuExecutionAcceleratorOrBuilder</h3>
<div class="member-signature"><span class="return-type"><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder.html" title="interface in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder</a></span>&nbsp;<span class="element-name">getGpuExecutionAcceleratorOrBuilder</span><wbr><span class="parameters">(int&nbsp;index)</span></div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on GPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
&#64;&#64;       "auto_mixed_precision", "gpu_io".
&#64;&#64;
&#64;&#64;       For "tensorrt", the following parameters can be specified:
&#64;&#64;         "precision_mode": The precision used for optimization.
&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
&#64;&#64;
&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
&#64;&#64;
&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
&#64;&#64;
&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
&#64;&#64;         can use temporarily during execution. Default value is 1GB.
&#64;&#64;
&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
&#64;&#64;       the model will try to use FP16 for better performance.
&#64;&#64;       This optimization can not be set with "tensorrt".
&#64;&#64;
&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
&#64;&#64;       be executed using TensorFlow Callable API to set input and output
&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
&#64;&#64;       object will be created on model creation and it will request all
&#64;&#64;       outputs for every model execution, which may impact the
&#64;&#64;       performance if a request does not require all outputs. This
&#64;&#64;       optimization will only take affect if the model instance is
&#64;&#64;       created with KIND_GPU.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code></div>
</section>
</li>
<li>
<section class="detail" id="getCpuExecutionAcceleratorList()">
<h3>getCpuExecutionAcceleratorList</h3>
<div class="member-signature"><span class="return-type"><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;<a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator</a>&gt;</span>&nbsp;<span class="element-name">getCpuExecutionAcceleratorList</span>()</div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on CPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code></div>
</section>
</li>
<li>
<section class="detail" id="getCpuExecutionAccelerator(int)">
<h3>getCpuExecutionAccelerator</h3>
<div class="member-signature"><span class="return-type"><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.html" title="class in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator</a></span>&nbsp;<span class="element-name">getCpuExecutionAccelerator</span><wbr><span class="parameters">(int&nbsp;index)</span></div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on CPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code></div>
</section>
</li>
<li>
<section class="detail" id="getCpuExecutionAcceleratorCount()">
<h3>getCpuExecutionAcceleratorCount</h3>
<div class="member-signature"><span class="return-type">int</span>&nbsp;<span class="element-name">getCpuExecutionAcceleratorCount</span>()</div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on CPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code></div>
</section>
</li>
<li>
<section class="detail" id="getCpuExecutionAcceleratorOrBuilderList()">
<h3>getCpuExecutionAcceleratorOrBuilderList</h3>
<div class="member-signature"><span class="return-type"><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;? extends <a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder.html" title="interface in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder</a>&gt;</span>&nbsp;<span class="element-name">getCpuExecutionAcceleratorOrBuilderList</span>()</div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on CPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code></div>
</section>
</li>
<li>
<section class="detail" id="getCpuExecutionAcceleratorOrBuilder(int)">
<h3>getCpuExecutionAcceleratorOrBuilder</h3>
<div class="member-signature"><span class="return-type"><a href="ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder.html" title="interface in inference">ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder</a></span>&nbsp;<span class="element-name">getCpuExecutionAcceleratorOrBuilder</span><wbr><span class="parameters">(int&nbsp;index)</span></div>
<div class="block"><pre>
&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
&#64;&#64;
&#64;&#64;       The preferred execution provider to be used if the model instance
&#64;&#64;       is deployed on CPU.
&#64;&#64;
&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
&#64;&#64;       and no parameters are required.
&#64;&#64;
 </pre>

 <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code></div>
</section>
</li>
</ul>
</section>
</li>
</ul>
</section>
<!-- ========= END OF CLASS DATA ========= -->
</main>
<footer role="contentinfo">
<hr>
<p class="legal-copy"><small>Copyright &#169; 2026. All rights reserved.</small></p>
</footer>
</div>
</div>
</body>
</html>
